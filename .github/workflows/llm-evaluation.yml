name: 🤖 LLM-as-a-Judge Evaluation

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:  # Allow manual trigger
    inputs:
      test_scope:
        description: 'Test scope'
        required: true
        default: 'single'
        type: choice
        options:
        - single
        - three_cases
        - full

jobs:
  llm-evaluation:
    runs-on: ubuntu-latest
    timeout-minutes: 15  # Prevent runaway costs

    env:
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
      JUDGE_MODEL: gpt-5

    steps:
    - name: 📥 Checkout code
      uses: actions/checkout@v4

    - name: 🐍 Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: 📦 Install dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt

    - name: 🔍 Verify environment
      run: |
        python --version
        python -c "import deepeval; print('✅ DeepEval:', deepeval.__version__)"
        python -c "import openai; print('✅ OpenAI client ready')"
        python -c "import anthropic; print('✅ Anthropic client ready')"

    - name: 🧪 Run LLM Evaluation (Single Test)
      if: github.event.inputs.test_scope != 'full' && github.event.inputs.test_scope != 'three_cases'
      run: |
        echo "🚀 Running single test case evaluation..."
        python -m pytest test_llm_evaluation.py \
          -k "test_case0 and test_correctness and claude" \
          --junitxml=test-results/junit.xml \
          --html=test-results/report.html \
          --self-contained-html \
          -v --tb=short

    - name: 🧪 Run LLM Evaluation (Three Cases)
      if: github.event.inputs.test_scope == 'three_cases'
      run: |
        echo "🚀 Running three test cases evaluation..."
        python -m pytest test_llm_evaluation.py \
          -k "(test_case0 or test_case1 or test_case2) and test_correctness" \
          --junitxml=test-results/junit.xml \
          --html=test-results/report.html \
          --self-contained-html \
          -v --tb=short --maxfail=3

    - name: 🧪 Run LLM Evaluation (Full Suite)
      if: github.event.inputs.test_scope == 'full'
      run: |
        echo "🚀 Running full evaluation suite..."
        echo "⚠️  This will cost approximately $10-20 USD"
        python -m pytest test_llm_evaluation.py \
          --junitxml=test-results/junit.xml \
          --html=test-results/report.html \
          --self-contained-html \
          -v --tb=short --maxfail=10

    - name: 📊 Simple Results Summary
      if: always()
      run: |
        echo "## 🤖 LLM-as-a-Judge Evaluation Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "📋 **Test Scope**: $(echo ${{ github.event.inputs.test_scope || 'single' }} | tr '[:lower:]' '[:upper:]')" >> $GITHUB_STEP_SUMMARY
        echo "🤖 **Judge Model**: GPT-5" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "📊 **Detailed results available in the test reports below**" >> $GITHUB_STEP_SUMMARY

    - name: 📤 Upload Test Reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: llm-evaluation-reports-${{ github.event.inputs.test_scope || 'single' }}
        path: test-results/
        retention-days: 30

    - name: 📋 Publish Test Results
      if: always()
      uses: dorny/test-reporter@v1
      with:
        name: 🤖 LLM Evaluation Results
        path: 'test-results/junit.xml'
        reporter: java-junit
        fail-on-error: false

    - name: 📈 Enhanced JUnit Report
      if: always()
      uses: EnricoMi/publish-unit-test-result-action@v2
      with:
        files: test-results/junit.xml
        check_name: "LLM Evaluation Detailed Results"
        comment_mode: always

    - name: 💬 Comment on PR
      if: github.event_name == 'pull_request' && always()
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');

          try {
            const xmlContent = fs.readFileSync('test-results/junit.xml', 'utf8');

            // Extract basic metrics (simplified parsing)
            const testsMatch = xmlContent.match(/tests="(\d+)"/);
            const failuresMatch = xmlContent.match(/failures="(\d+)"/);
            const timeMatch = xmlContent.match(/time="([\d.]+)"/);

            const tests = testsMatch ? testsMatch[1] : 'N/A';
            const failures = failuresMatch ? failuresMatch[1] : 'N/A';
            const time = timeMatch ? parseFloat(timeMatch[1]).toFixed(1) : 'N/A';

            const status = failures === '0' ? '✅ PASSED' : '❌ FAILED';
            const emoji = failures === '0' ? '🎉' : '🚨';
            const scope = '${{ github.event.inputs.test_scope || "single" }}';

            const comment = `${emoji} **LLM-as-a-Judge Evaluation Results**

            | Metric | Value |
            |--------|-------|
            | Status | ${status} |
            | Scope | ${scope} |
            | Tests Run | ${tests} |
            | Failures | ${failures} |
            | Duration | ${time}s |

            📊 **Detailed Reports**: Check the test results and uploaded artifacts below.

            🤖 Evaluated with **GPT-5 as judge** using **DeepEval + pytest**.`;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
          } catch (error) {
            console.log('Could not read test results:', error.message);
          }

    - name: 🚨 Fail on Test Failures
      if: always()
      run: |
        if [ -f test-results/junit.xml ]; then
          FAILURES=$(xmllint --xpath "//testsuite/@failures" test-results/junit.xml | sed 's/failures="//;s/"//')
          if [ "$FAILURES" != "0" ]; then
            echo "❌ Tests failed with $FAILURES failures"
            exit 1
          fi
          echo "✅ All tests passed!"
        else
          echo "⚠️  No test results found"
          exit 1
        fi